{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deap import algorithms\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TITANIC INPUT DATA\n",
    "#########################################################################\n",
    "\n",
    "train_data=[] # Create a bin to hold our training data.\n",
    "test_data=[]  # Create a bin to hold our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in CSVs, train and test\n",
    "\n",
    "with open('train.csv', 'r') as f1:\n",
    "    f1.readline()\n",
    "    for row in  csv.reader(f1):       # Skip through each row in the csv file\n",
    "        train_data.append(row)        # Add each row to the data variable\n",
    "    train_data = np.array(train_data) # Then convert from a list to a NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.csv', 'r') as f2:\n",
    "    f2.readline()\n",
    "    for row in csv.reader(f2):      # Skip through each row in the csv file\n",
    "        test_data.append(row)       # Add each row to the data variable\n",
    "    test_data = np.array(test_data) # Then convert from a list to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert strings to numbers so we can perform computational analysis    \n",
    "# The gender classifier in column 3: Male = 1, female = 0:\n",
    "train_data[train_data[0::,3] == 'male', 3] = 1\n",
    "train_data[train_data[0::,3] == 'female', 3] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embark C = 0, S = 1, Q = 2\n",
    "train_data[train_data[0::,10] == 'C', 10] = 0\n",
    "train_data[train_data[0::,10] == 'S', 10] = 1\n",
    "train_data[train_data[0::,10] == 'Q', 10] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transfer Null observations\n",
    "# So where there is no price, I will assume price on median of that class\n",
    "# Where there is no age I will give median of all ages\n",
    "\n",
    "# All the ages with no data make the median of the data\n",
    "train_data[train_data[0::,4] == '',4] = np.median(train_data[train_data[0::,4]\\\n",
    "                                           != '',4].astype(np.float))\n",
    "# All missing embarks just make them embark from most common place\n",
    "train_data[train_data[0::,10] == '',10] = np.round(np.mean(train_data[train_data[0::,10]\\\n",
    "                                                   != '',10].astype(np.float)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.delete(train_data,[2,7,9],1) #remove the name data, cabin and ticket\n",
    "# I need to do the same with the test data now so that the columns are in the same\n",
    "# as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I need to convert all strings to integer classifiers:\n",
    "# male = 1, female = 0:\n",
    "test_data[test_data[0::,2] == 'male',2] = 1\n",
    "test_data[test_data[0::,2] == 'female',2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Embark C = 0, S = 1, Q = 2\n",
    "test_data[test_data[0::,9] == 'C',9] = 0 \n",
    "test_data[test_data[0::,9] == 'S',9] = 1\n",
    "test_data[test_data[0::,9] =='Q',9] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the ages with no data make the median of the data\n",
    "test_data[test_data[0::,3] == '',3] = np.median(test_data[test_data[0::,3]\\\n",
    "                                           != '',3].astype(np.float))\n",
    "# All missing embarks just make them embark from most common place\n",
    "test_data[test_data[0::,9] == '',9] = np.round(np.median(test_data[test_data[0::,9]\\\n",
    "                                                   != '',9].astype(np.float)))\n",
    "# All the missing prices assume median of their respective class\n",
    "for i in range(np.size(test_data[0::,0])):\n",
    "    if test_data[i,7] == '':\n",
    "        test_data[i,7] = np.median(test_data[(test_data[0::,7] != '') &\\\n",
    "                                             (test_data[0::,0] == test_data[i,0])\\\n",
    "            ,7].astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = np.delete(test_data,[1,6,8],1) # Remove the name data, cabin and ticket\n",
    "\n",
    "titanic_x = train_data[0::,1::]\n",
    "titanic_x = titanic_x.astype(float)\n",
    "titanic_x = titanic_x / titanic_x.max(axis=0)\n",
    "titanic_y = train_data[0::,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "ind = int(len(titanic_x) * .8)\n",
    "train_x = titanic_x[:ind]\n",
    "train_y = titanic_y[:ind]\n",
    "test_x = titanic_x[ind:]\n",
    "test_y = titanic_y[ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,-2.0))\n",
    "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse(x):\n",
    "    if abs(float(x)) < 1e-9:\n",
    "        return 1\n",
    "    return np.power(float(x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pset = gp.PrimitiveSet(\"MAIN\", arity=7)\n",
    "pset.addPrimitive(np.add, arity=2)\n",
    "pset.addPrimitive(np.subtract, arity=2)\n",
    "pset.addPrimitive(np.multiply, arity=2)\n",
    "pset.addPrimitive(np.negative, arity=1)\n",
    "pset.addPrimitive(inverse, arity=1)\n",
    "pset.renameArguments(ARG0='Pclass')\n",
    "pset.renameArguments(ARG1='Sex')\n",
    "pset.renameArguments(ARG2='Age')\n",
    "pset.renameArguments(ARG3='SibSp')\n",
    "pset.renameArguments(ARG4='Parch')\n",
    "pset.renameArguments(ARG5='Fare')\n",
    "pset.renameArguments(ARG6='Embarked')\n",
    "\n",
    "pset.addEphemeralConstant(\"const\", lambda: random.randint(-10, 10))\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"compile\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalSymbReg(individual, x, y, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    r = []\n",
    "    for z in x:\n",
    "\n",
    "        a = func(float(z[0]), float(z[1]), float(z[2]),float(z[3]),float(z[4]),float(z[5]),float(z[6]))\n",
    "        r.append(a)\n",
    "    results = [0 if m > 0 else 1 for m in r]\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for t in zip(results, y):\n",
    "        if t[0] != int(t[1]):\n",
    "            if int(t[1]):\n",
    "                fp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "    return (fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toolbox.register(\"evaluate\", evalSymbReg, x=titanic_x, y=titanic_y, pset=pset)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", gp.cxOnePoint)\n",
    "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
    "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#toolbox.register()\n",
    "\n",
    "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=15))\n",
    "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = range(100)\n",
    "avg_list = []\n",
    "max_list = []\n",
    "min_list = []\n",
    "avg_list2 = []\n",
    "max_list2 = []\n",
    "min_list2 = []\n",
    "\n",
    "pop = toolbox.population(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the entire population\n",
    "fitnesses = list(map(toolbox.evaluate, pop))\n",
    "\n",
    "for ind, fit in zip(pop, fitnesses):\n",
    "    ind.fitness.values = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutShrink(individual):\n",
    "    ##This operator shrinks the *individual* by chosing randomly a branch and\n",
    "    ##replacing it with one of the branch's arguments (also randomly chosen).\n",
    "    ##:param individual: The tree to be shrinked.\n",
    "    ##:returns: A tuple of one tree.\n",
    "    \n",
    "    # We don't want to \"shrink\" the root\n",
    "    \n",
    "    if len(individual) < 3 or individual.height <= 1:\n",
    "        return individual,\n",
    "    \n",
    "    iprims = []\n",
    "    for i, node in enumerate(individual[1:], 1):\n",
    "        if isinstance(node, Primitive) and node.ret in node.args:\n",
    "            iprims.append((i, node))\n",
    "            \n",
    "    if len(iprims) != 0:\n",
    "        index, prim = random.choice(iprims)\n",
    "        arg_idx = random.choice([i for i, type_ in enumerate(prim.args) \n",
    "                                 if type_ == prim.ret])\n",
    "        rindex = index + 1\n",
    "        for _ in range(arg_idx + 1):\n",
    "            rslice = individual.searchSubtree(index)\n",
    "            individual[slice_] = subtree\n",
    "            \n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Generation 0 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 76.057\n",
      "  Std 122.00842491811785\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 420.568\n",
      "  Std 210.20697271023147\n",
      "-- Generation 1 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 42.29\n",
      "  Std 100.09822126291755\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 478.757\n",
      "  Std 169.4499039568922\n",
      "-- Generation 2 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 31.619\n",
      "  Std 92.1033649711019\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 497.191\n",
      "  Std 153.05842191464026\n",
      "-- Generation 3 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.107\n",
      "  Std 84.65451878665426\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 502.528\n",
      "  Std 143.73231096729782\n",
      "-- Generation 4 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 25.248\n",
      "  Std 77.35694213191212\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 508.321\n",
      "  Std 131.36719514018714\n",
      "-- Generation 5 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.16\n",
      "  Std 66.686763304272\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 521.247\n",
      "  Std 108.94776726027949\n",
      "-- Generation 6 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 19.661\n",
      "  Std 67.4747514185862\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 516.493\n",
      "  Std 115.70358659523016\n",
      "-- Generation 7 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 20.428\n",
      "  Std 67.55904688492875\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 517.413\n",
      "  Std 112.62881705407352\n",
      "-- Generation 8 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 23.195\n",
      "  Std 73.29599562731923\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 515.747\n",
      "  Std 115.35292363438418\n",
      "-- Generation 9 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.26\n",
      "  Std 71.04030123810006\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 511.822\n",
      "  Std 116.66595182828638\n",
      "-- Generation 10 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.791\n",
      "  Std 84.34852292126993\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 497.319\n",
      "  Std 139.81426693653262\n",
      "-- Generation 11 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.466\n",
      "  Std 76.98462732260253\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 506.787\n",
      "  Std 122.68205912438876\n",
      "-- Generation 12 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.827\n",
      "  Std 82.15840231528361\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 500.486\n",
      "  Std 133.61049286639135\n",
      "-- Generation 13 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.87\n",
      "  Std 81.93910604833323\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 499.637\n",
      "  Std 133.22834244634288\n",
      "-- Generation 14 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.777\n",
      "  Std 79.69901675052209\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.457\n",
      "  Std 127.2981702578634\n",
      "-- Generation 15 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 33.186\n",
      "  Std 81.42618377401706\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 498.564\n",
      "  Std 132.90884810275054\n",
      "-- Generation 16 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 30.242\n",
      "  Std 75.0346415730761\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 503.192\n",
      "  Std 122.05705688734267\n",
      "-- Generation 17 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.35\n",
      "  Std 83.50229637560874\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 496.355\n",
      "  Std 137.86017182275663\n",
      "-- Generation 18 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.658\n",
      "  Std 75.03323954088614\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 502.702\n",
      "  Std 121.36003129531576\n",
      "-- Generation 19 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 27.981\n",
      "  Std 71.60242062249013\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 505.641\n",
      "  Std 112.81164886216303\n",
      "-- Generation 20 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.22\n",
      "  Std 66.8637689634678\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 509.371\n",
      "  Std 105.73594166129148\n",
      "-- Generation 21 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 22.427\n",
      "  Std 65.69788939532228\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 511.68\n",
      "  Std 102.80142800564577\n",
      "-- Generation 22 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 23.092\n",
      "  Std 66.39582468800279\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 508.713\n",
      "  Std 107.0109463139169\n",
      "-- Generation 23 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.92\n",
      "  Std 71.661367556027\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 504.494\n",
      "  Std 112.65266958221616\n",
      "-- Generation 24 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 21.862\n",
      "  Std 63.79124513599026\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 509.873\n",
      "  Std 100.39097006703335\n",
      "-- Generation 25 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 20.636\n",
      "  Std 62.625997029987474\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 509.893\n",
      "  Std 99.31338052347228\n",
      "-- Generation 26 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.855\n",
      "  Std 71.30238407655105\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 503.253\n",
      "  Std 113.29305800003812\n",
      "-- Generation 27 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 20.111\n",
      "  Std 62.935146611412605\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 510.942\n",
      "  Std 95.42907647043414\n",
      "-- Generation 28 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.262\n",
      "  Std 58.822116214906785\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 512.473\n",
      "  Std 90.12016018072764\n",
      "-- Generation 29 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.168\n",
      "  Std 59.26229641179964\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 513.488\n",
      "  Std 88.01612270487686\n",
      "-- Generation 30 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 19.142\n",
      "  Std 61.19627305645336\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 511.024\n",
      "  Std 94.02909881520713\n",
      "-- Generation 31 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 15.078\n",
      "  Std 52.1020337031099\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 516.838\n",
      "  Std 79.82306531322894\n",
      "-- Generation 32 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 17.038\n",
      "  Std 56.724391191091684\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 514.406\n",
      "  Std 85.24908893354834\n",
      "-- Generation 33 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 16.16\n",
      "  Std 53.84275624445688\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 514.946\n",
      "  Std 81.39338476805085\n",
      "-- Generation 34 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 19.637\n",
      "  Std 63.03696717799802\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 510.063\n",
      "  Std 95.12129641147675\n",
      "-- Generation 35 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.697\n",
      "  Std 60.23302408977985\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 511.984\n",
      "  Std 91.62733076980923\n",
      "-- Generation 36 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.197\n",
      "  Std 59.37337948104353\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 512.975\n",
      "  Std 89.13276824490514\n",
      "-- Generation 37 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 21.284\n",
      "  Std 63.06621396595803\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 508.68\n",
      "  Std 93.91843056610364\n",
      "-- Generation 38 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.956\n",
      "  Std 71.52847030378882\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.741\n",
      "  Std 110.6081458076214\n",
      "-- Generation 39 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 23.983\n",
      "  Std 73.02432958268086\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.884\n",
      "  Std 113.20257304496204\n",
      "-- Generation 40 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.831\n",
      "  Std 72.21518149946034\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 500.513\n",
      "  Std 111.49684224676511\n",
      "-- Generation 41 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 25.713\n",
      "  Std 74.34420374851021\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 498.419\n",
      "  Std 114.67996965032744\n",
      "-- Generation 42 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 31.397\n",
      "  Std 84.30378040752383\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 488.189\n",
      "  Std 130.8652561950649\n",
      "-- Generation 43 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.512\n",
      "  Std 77.29140868168984\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.197\n",
      "  Std 122.0404940624218\n",
      "-- Generation 44 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.231\n",
      "  Std 74.80054571324997\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 495.114\n",
      "  Std 117.8385972591325\n",
      "-- Generation 45 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.458\n",
      "  Std 83.06704663101969\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 491.289\n",
      "  Std 127.7633651677977\n",
      "-- Generation 46 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 31.767\n",
      "  Std 84.47305316489987\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 487.884\n",
      "  Std 131.81219421586155\n",
      "-- Generation 47 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.419\n",
      "  Std 76.86261405260687\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 495.038\n",
      "  Std 120.15230566243822\n",
      "-- Generation 48 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.067\n",
      "  Std 76.06849880863957\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 495.703\n",
      "  Std 116.5247561293309\n",
      "-- Generation 49 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.152\n",
      "  Std 76.15914190693064\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 494.4\n",
      "  Std 118.97760293433387\n",
      "-- Generation 50 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.917\n",
      "  Std 73.84911719851497\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 496.755\n",
      "  Std 113.45607509075926\n",
      "-- Generation 51 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 27.009\n",
      "  Std 76.52323123731773\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 493.233\n",
      "  Std 120.99655660802914\n",
      "-- Generation 52 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.95\n",
      "  Std 79.87971895293573\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 490.526\n",
      "  Std 124.26410311912275\n",
      "-- Generation 53 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 30.073\n",
      "  Std 81.45024046005021\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 490.589\n",
      "  Std 124.33355974554908\n",
      "-- Generation 54 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 22.273\n",
      "  Std 67.503795974745\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.103\n",
      "  Std 105.73172840259438\n",
      "-- Generation 55 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.112\n",
      "  Std 80.17005336158883\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 491.46\n",
      "  Std 125.03525262900872\n",
      "-- Generation 56 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.64\n",
      "  Std 70.94995701196724\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 498.843\n",
      "  Std 109.04874300513505\n",
      "-- Generation 57 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 32.249\n",
      "  Std 85.1252547661386\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 487.745\n",
      "  Std 131.0973530434539\n",
      "-- Generation 58 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.526\n",
      "  Std 77.44274868572268\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 491.739\n",
      "  Std 120.90904382634098\n",
      "-- Generation 59 --\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 27.431\n",
      "  Std 77.69223409710908\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 494.486\n",
      "  Std 118.7352087798729\n",
      "-- Generation 60 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.301\n",
      "  Std 73.83793333375468\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 495.94\n",
      "  Std 114.60193017571738\n",
      "-- Generation 61 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.294\n",
      "  Std 79.93213098623106\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 491.106\n",
      "  Std 124.15461636201859\n",
      "-- Generation 62 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.698\n",
      "  Std 78.6044451414804\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.379\n",
      "  Std 119.73778584473652\n",
      "-- Generation 63 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.667\n",
      "  Std 81.61155623439612\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 490.245\n",
      "  Std 124.68388418316141\n",
      "-- Generation 64 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 30.782\n",
      "  Std 82.63667754695852\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 489.816\n",
      "  Std 124.79945570394128\n",
      "-- Generation 65 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.328\n",
      "  Std 77.62517900784513\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.0\n",
      "  Std 117.20539236741624\n",
      "-- Generation 66 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 29.157\n",
      "  Std 81.7136484988891\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 489.744\n",
      "  Std 127.28516199463301\n",
      "-- Generation 67 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 31.341\n",
      "  Std 83.91953717103068\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 485.518\n",
      "  Std 129.85326979325563\n",
      "-- Generation 68 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 25.914\n",
      "  Std 76.8091570322185\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.419\n",
      "  Std 120.27213908050365\n",
      "-- Generation 69 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 28.393\n",
      "  Std 79.55437480742337\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 490.66\n",
      "  Std 121.65813741793016\n",
      "-- Generation 70 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 25.934\n",
      "  Std 76.20222860258092\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 494.297\n",
      "  Std 115.95651249929855\n",
      "-- Generation 71 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 24.04\n",
      "  Std 75.50515479091477\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 496.352\n",
      "  Std 115.26200629869332\n",
      "-- Generation 72 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.26\n",
      "  Std 77.20023575093538\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.846\n",
      "  Std 118.19064380905961\n",
      "-- Generation 73 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 26.911\n",
      "  Std 79.2400976715703\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 492.333\n",
      "  Std 121.40437434870282\n",
      "-- Generation 74 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 30.355\n",
      "  Std 82.78844711069293\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 486.333\n",
      "  Std 127.77491189979337\n",
      "-- Generation 75 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 25.016\n",
      "  Std 76.41353115777336\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 493.748\n",
      "  Std 116.50714354064309\n",
      "-- Generation 76 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 20.265\n",
      "  Std 68.56073785338079\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 500.211\n",
      "  Std 103.07912727123757\n",
      "-- Generation 77 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 19.258\n",
      "  Std 62.896354711541115\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.662\n",
      "  Std 94.90691100230804\n",
      "-- Generation 78 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 21.72\n",
      "  Std 69.81685756319888\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 496.34\n",
      "  Std 106.37929497792332\n",
      "-- Generation 79 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 21.73\n",
      "  Std 69.30968979875757\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 496.912\n",
      "  Std 105.50403905064508\n",
      "-- Generation 80 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 19.93\n",
      "  Std 67.24634636915228\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 499.331\n",
      "  Std 101.68836432453804\n",
      "-- Generation 81 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 20.395\n",
      "  Std 68.83451877510294\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 497.369\n",
      "  Std 106.15788637213898\n",
      "-- Generation 82 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 18.604\n",
      "  Std 67.02206490402993\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 499.729\n",
      "  Std 102.19979236280291\n",
      "-- Generation 83 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 17.432\n",
      "  Std 64.07315643855857\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 501.165\n",
      "  Std 96.56949712512736\n",
      "-- Generation 84 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 12.73\n",
      "  Std 52.045548320677725\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 508.38\n",
      "  Std 77.0982075018609\n",
      "-- Generation 85 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 14.125\n",
      "  Std 57.14582552557973\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 505.628\n",
      "  Std 85.69430328790847\n",
      "-- Generation 86 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 9.736\n",
      "  Std 45.89375016274003\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 511.909\n",
      "  Std 65.64838702512039\n",
      "-- Generation 87 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 14.086\n",
      "  Std 58.100332219359984\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 504.529\n",
      "  Std 89.11072415259574\n",
      "-- Generation 88 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 12.873\n",
      "  Std 51.7075900714779\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 506.961\n",
      "  Std 77.81383860856626\n",
      "-- Generation 89 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 12.792\n",
      "  Std 52.30752083591804\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 506.356\n",
      "  Std 78.31657081358975\n",
      "-- Generation 90 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 10.978\n",
      "  Std 49.708666407378104\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 507.205\n",
      "  Std 76.09789073949409\n",
      "-- Generation 91 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 11.071\n",
      "  Std 46.85652525529395\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 506.261\n",
      "  Std 74.89518595343742\n",
      "-- Generation 92 --\n",
      "  Min 0.0\n",
      "  Max 342.0\n",
      "  Avg 7.848\n",
      "  Std 40.46908568277766\n",
      "  Min 0.0\n",
      "  Max 549.0\n",
      "  Avg 510.73\n",
      "  Std 63.023797886195\n",
      "-- Generation 93 --\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "DEAP : Error in tree evaluation : Python cannot evaluate a tree higher than 90. To avoid this problem, you should use bloat control on your operators. See the DEAP documentation for more information. DEAP will now abort.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/Users/pallavichetia/anaconda/lib/python3.6/site-packages/deap-1.0.2-py3.6.egg/deap/gp.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(expr, pset)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-8a345bd3afde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mfitnesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitnesses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-6bb6020e6768>\u001b[0m in \u001b[0;36mevalSymbReg\u001b[0;34m(individual, x, y, pset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevalSymbReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavichetia/anaconda/lib/python3.6/site-packages/deap-1.0.2-py3.6.egg/deap/gp.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(expr, pset)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;34m\"To avoid this problem, you should use bloat control on your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;34m\"operators. See the DEAP documentation for more information. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \"DEAP will now abort.\").with_traceback(traceback)\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompileADF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pallavichetia/anaconda/lib/python3.6/site-packages/deap-1.0.2-py3.6.egg/deap/gp.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(expr, pset)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lambda {args}: {code}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: DEAP : Error in tree evaluation : Python cannot evaluate a tree higher than 90. To avoid this problem, you should use bloat control on your operators. See the DEAP documentation for more information. DEAP will now abort."
     ]
    }
   ],
   "source": [
    "# Begin the evolution\n",
    "for g in gen:\n",
    "    print(\"-- Generation %i --\" % g)\n",
    "\n",
    "    # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < 0.5:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "    if random.random() < 0.2:\n",
    "        indRange = len(mutant)\n",
    "        location = random.randint(1,indRange-1)\n",
    "        subtree_slice = mutant.searchSubtree(location)\n",
    "        ind = gp.genHalfAndHalf(pset=pset, min_=1, max_=2)\n",
    "        mutant[subtree_slice] = ind[:]\n",
    "        del mutant.fitness.values\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for mutant in offspring:\n",
    "        if random.random() < 0.2:\n",
    "            gp.mutNodeReplacement(mutant, pset)\n",
    "            del mutant.fitness.values\n",
    "            \n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Replace population\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[0] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    g_max = max(fits)\n",
    "    g_min = min(fits)\n",
    "        \n",
    "    avg_list.append(mean)\n",
    "    max_list.append(g_max)\n",
    "    min_list.append(g_min)\n",
    "\n",
    "    print(\"  Min %s\" % g_min)\n",
    "    print(\"  Max %s\" % g_max)\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "\n",
    "    # Gather all the fitnesses in one list and print the stats\n",
    "    fits = [ind.fitness.values[1] for ind in pop]\n",
    "\n",
    "    length = len(pop)\n",
    "    mean = sum(fits) / length\n",
    "    sum2 = sum(x*x for x in fits)\n",
    "    std = abs(sum2 / length - mean**2)**0.5\n",
    "    g_max = max(fits)\n",
    "    g_min = min(fits)\n",
    "\n",
    "    avg_list2.append(mean)\n",
    "    max_list2.append(g_max)\n",
    "    min_list2.append(g_min)\n",
    "    print(\"  Min %s\" % g_min)\n",
    "    print(\"  Max %s\" % g_max)\n",
    "    print(\"  Avg %s\" % mean)\n",
    "    print(\"  Std %s\" % std)\n",
    "\n",
    "print(\"-- End of (successful) evolution --\")\n",
    "\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Best individual is %s, %s\" % (best_ind, best_ind.fitness.values))\n",
    "\n",
    "worst_ind = tools.selWorst(pop, 1)[0]\n",
    "print(\"Worst individual is %s, %s\" % (worst_ind, worst_ind.fitness.values))\n",
    "\n",
    "a_given_individual = toolbox.population(n=1)[0]\n",
    "a_given_individual.fitness.values = toolbox.evaluate(a_given_individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pareto_dominance(ind1, ind2):\n",
    "    not_equal = False\n",
    "    for value_1, value_2 in zip(ind1.fitness.values, ind2.fitness.values):\n",
    "        if value_1 > value_2:\n",
    "            return False\n",
    "        elif value_1 < value_2:\n",
    "            not_equal = True\n",
    "    return not_equal\n",
    "\n",
    "dominated = [ind for ind in pop if pareto_dominance(a_given_individual, ind)]\n",
    "dominators = [ind for ind in pop if pareto_dominance(ind, a_given_individual)]\n",
    "others = [ind for ind in pop if not ind in dominated and not ind in dominators]\n",
    "    \n",
    "for ind in dominators: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'r.', alpha=0.7)\n",
    "for ind in dominated: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'g.', alpha=0.7)\n",
    "for ind in others: plt.plot(ind.fitness.values[0], ind.fitness.values[1], 'k.', alpha=0.7, ms=3)\n",
    "plt.plot(a_given_individual.fitness.values[0], a_given_individual.fitness.values[1], 'bo', ms=6);\n",
    "plt.xlabel('false positive');\n",
    "plt.ylabel('false negative');\n",
    "plt.title('Objective space');\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(gen, avg_list, label=\"average\")\n",
    "plt.plot(gen, min_list, label=\"minimum\")\n",
    "plt.plot(gen, max_list, label=\"maximum\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"false positives\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(gen, avg_list2, label=\"average\")\n",
    "plt.plot(gen, min_list2, label=\"minimum\")\n",
    "plt.plot(gen, max_list2, label=\"maximum\")\n",
    "plt.xlabel(\"Generation\")\n",
    "plt.ylabel(\"false negatives\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(individual, x, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    r = []\n",
    "    for z in x:\n",
    "\n",
    "        a = func(float(z[0]), float(z[1]), float(z[2]),float(z[3]),float(z[4]),float(z[5]),float(z[6]))\n",
    "        r.append(a)\n",
    "    results = [0 if m > 0 else 1 for m in r]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(individual, x, y, pset):\n",
    "    func = gp.compile(expr=individual, pset=pset)\n",
    "    r = []\n",
    "    for z in x:\n",
    "\n",
    "        a = func(float(z[0]), float(z[1]), float(z[2]),float(z[3]),float(z[4]),float(z[5]),float(z[6]))\n",
    "        r.append(a)\n",
    "    results = [0 if m > 0 else 1 for m in r]\n",
    "    correct = 0\n",
    "    for t in zip(results, y):\n",
    "        if t[0] == int(t[1]):\n",
    "            correct+=1\n",
    "\n",
    "    return (correct) / len(y)\n",
    "\n",
    "paretoFront = tools.ParetoFront()\n",
    "\n",
    "paretoFront.update(pop)\n",
    "for i in range(6):\n",
    "\n",
    "    print(len(paretoFront))\n",
    "    ind = paretoFront[int(len(paretoFront)/6*i)]\n",
    "    print(\"individual is %s, %s\" % (ind, ind.fitness.values))\n",
    "    nodes, edges, labels = gp.graph(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for ind in paretoFront:\n",
    "    x.append(ind.fitness.values[0])\n",
    "    y.append(ind.fitness.values[1])\n",
    "\n",
    "paretoArea = np.trapz(np.asarray(y), np.asarray(x))\n",
    "print(\"The pareto area is %d\" %paretoArea)\n",
    "\n",
    "#for ind in paretoFront: plt.plot(ind.fitness.values[0], ind.fitness.values[1], '.r-', alpha=0.7, ms=3)\n",
    "plt.plot(x, y, '.r-')\n",
    "d = scipy.zeros(len(y))\n",
    "plt.fill_between(x, y, where=y>d)\n",
    "\n",
    "\n",
    "plt.xlabel('false positive');\n",
    "plt.ylabel('false negative');\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
